# WeatherIQ â€“ Intelligent Weather Analytics System

WeatherIQ is a full-stack weather data analytics system built in 4 phases. It fetches real-time, forecasted, and historical weather data, stores and processes it, and uses vector embeddings to support Retrieval-Augmented Generation (RAG) for intelligent query responses.

---

## ğŸŒ Project Architecture

```
                 OpenWeatherMap API
                          |
              --------------------------
              |         |         |    |
        Real-time  Forecast  Historical  Air Quality
              |         |         |    |
              +---------+---------+----+
                        |
                Phase 2: Collectors
                        |
                   PostgreSQL
                        |
                Phase 3: Ingestion
             (Transform + Validation)
                        |
         +--------------+-------------+
         |                            |
  SentenceTransformer           pgvector
         |                            |
         +--------------+-------------+
                        |
              Phase 4: FastAPI RAG API
                        |
                      Client
```

---

## ğŸ“‚ Folder Structure

```
WeatherIQ/
â”œâ”€â”€ phase1/                              # Infrastructure Setup
â”‚   â””â”€â”€ airflow_local/
â”‚   â””â”€â”€â”€â”€ dags/
â”‚
â”œâ”€â”€ phase2/                              # Weather Data Collection
â”‚   â”œâ”€â”€ collectors/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ realtime_collector.py
â”‚   â”‚   â”œâ”€â”€ historical_collector.py
â”‚   â”‚   â”œâ”€â”€ forecast_collector.py
â”‚   â”‚   â”œâ”€â”€ air_quality_collector.py
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”œâ”€â”€db/ db.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ phase3/                              # Data Ingestion
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ city.list.json.gz
â”‚   â”‚   â”œâ”€â”€ city.list.json
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€bulk_trans_val.py
â”‚   â”œâ”€â”€ collectors/
â”‚   â”‚   â””â”€â”€ realtime_collector.py
â”‚
â”‚
â”‚
â”œâ”€â”€ phase4/                              # RAG System
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ rag_api.py                   # FastAPI application
â”‚   â”œâ”€â”€ embeddings/
â”‚       â”œâ”€â”€ embedder.py                 # Embedding generation
â”‚       â”œâ”€â”€ storage.py                  # pgvector search and storage
â”œâ”€â”€ Testing/
â”‚     â”œâ”€â”€ test_bulk_trans_val.py  
â”‚     â”œâ”€â”€ test_embedder.py 
â”‚     â”œâ”€â”€ test_storage.py  
â”‚     â””â”€â”€ test_rag_api.py
â”‚
â”‚
â”‚
â”œâ”€â”€ db.py
â”œâ”€â”€ main.py
â”œâ”€â”€ models.py
â”œâ”€â”€ weather_service.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ architecture.png                    # Architecture Diagram
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Phase-wise Breakdown

### âœ… Phase 1: Infrastructure
- Setup PostgreSQL with pgvector
- FastAPI base initialized
- Optional: Docker/WSL setup for Airflow

### âœ… Phase 2: Weather Data Collectors
- Fetches real-time, historical, forecast, and air quality data
- Stores raw and structured data into PostgreSQL

### âœ… Phase 3: Ingestion Pipelines
- Uses transformation and validation logic
- Scheduled with Airflow to run ETL jobs

### âœ… Phase 4: RAG System
- SentenceTransformer for embeddings
- pgvector stores & searches embeddings
- FastAPI provides top-3 matching results based on similarity

---

## ğŸ‘¨â€ğŸ’» Technologies Used
- FastAPI
- PostgreSQL + pgvector
- Apache Airflow
- SentenceTransformer
- OpenWeatherMap API

---

## âš™ï¸ Setup Instructions

1. **PostgreSQL Setup**
   - Ensure pgvector extension is installed and enabled
2. **Install Requirements**
   ```bash
   pip install -r requirements.txt
   ```
3. **Run FastAPI**
   ```bash
   uvicorn phase4.api.rag_api:app --reload
   ```
4. **Access Docs**
   - http://127.0.0.1:8000/docs

---

## âš™ï¸ Setup Instructions for **PostgreSQL Setup** with pgvector extension is installed and enabled

# Step 1: Install PostgreSQL 16 (if not installed via Homebrew)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
brew update
brew install postgresql@16

# Link PostgreSQL 16 to make it the default version
brew link postgresql@16 --force

# Step 2: Start PostgreSQL service
brew services start postgresql@16

# Step 3: Install pgvector extension
brew install pgvector

# Step 4: Connect to PostgreSQL and enable pgvector
psql postgres

-- Inside psql prompt, run:
CREATE EXTENSION IF NOT EXISTS vector;

-- Optionally create your database and enable pgvector in it:
CREATE DATABASE poc;
\c poc
CREATE EXTENSION IF NOT EXISTS vector;

-- Quit psql
\q

# Step 5: (Optional) Create a sample table using vector
psql -d poc -U postgres -c "
CREATE TABLE weather_vectors (
    id SERIAL PRIMARY KEY,
    city TEXT,
    embedding VECTOR(384)
);
"
---
## âš™ï¸ Setup Instructions for Airflow

# Step 1: Create and activate a virtual environment
python3 -m venv airflow_venv
source airflow_venv/bin/activate

# Step 2: Export Airflow environment variables
export AIRFLOW_HOME=~/airflow
export AIRFLOW__CORE__EXECUTOR=LocalExecutor
export AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:yourpassword@localhost:5432/airflow

# If you want to use SQLite instead (simple testing only), use:
# export AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:///$AIRFLOW_HOME/airflow.db

# Step 3: Install Airflow with constraints (change version if needed)
AIRFLOW_VERSION=2.7.2
PYTHON_VERSION="$(python --version | cut -d " " -f 2 | cut -d "." -f 1,2)"
CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"

pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"

# Step 4: Initialize Airflow database
airflow db init

# Step 5: Create Airflow user (admin)
airflow users create \
  --username admin \
  --firstname Admin \
  --lastname User \
  --role Admin \
  --email admin@example.com \
  --password admin

# Step 6: Start Airflow services
airflow webserver --port 8080 &  # Wait a few seconds until the webserver is ready
airflow scheduler &


You can then access the Airflow UI at:
ğŸ‘‰ http://localhost:8080
Login with username admin and password admin.


---


## ğŸ”— GitHub Repository

### Repository: [WeatherIQ](https://github.com/your-username/WeatherIQ)

Push the project using:
```bash
git init
git remote add origin https://github.com/your-username/WeatherIQ.git
git add .
git commit -m "Initial commit"
git push -u origin master
```

---
